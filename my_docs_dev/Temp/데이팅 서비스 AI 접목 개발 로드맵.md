# 데이팅 서비스 AI 접목 개발 로드맵(초안)

작성자: 전규현

대상 독자: 개발팀, 기획팀, 경영진

최종 수정일: 2025-10-02

관련 문서:

- [전통적인 박스 시스템](../../munto_docs/전통적인%20박스%20시스템.md)
- [AI활용 박스 시스템](../../munto_docs/AI활용%20박스%20시스템.md)
- [AI 기반 수익 극대화 추천 시스템 설계서](./AI%20기반%20수익%20극대화%20추천%20시스템%20설계서.md)
- [단계별 데이터 수집 요구사항](./Level%203%20수익%20최적화를%20위한%20추가%20데이터%20수집%20요구사항.md)

---

## Executive Summary

데이팅 서비스 출시부터 AI 완전 적용까지 **18개월 로드맵**입니다. Cursor, Claude 같은 AI 코딩 도구를 적극 활용하여 **데이터 사이언티스트 1명**으로 전체 개발을 진행합니다. 서비스 시작 후 3개월간 데이터 수집에 집중하고, 가장 중요한 2개 모델(친구 수락 확률, 이탈 확률)을 우선 개발합니다. Level 2 모델이 안정화되면 Level 3 수익 최적화를 시작하며, 단계적으로 전체 시스템을 고도화합니다. 총 투자 2억원으로 연 3.6억원 추가 수익 창출, 회수 기간 7개월 예상입니다.

---

## 1. 전체 로드맵 개요

### 1.1 타임라인

```
Month 0-3:   Phase 0 - 서비스 출시 및 데이터 수집
Month 3-6:   Phase 1 - Level 2 준비 (분석, 학습 계획)
Month 6-9:   Phase 2 - Level 2 핵심 모델 개발 (2개)
Month 9-12:  Phase 3 - Level 2 적용 및 검증
Month 12-15: Phase 4 - Level 3 개발 (수익 최적화)
Month 15-18: Phase 5 - Level 3 적용 및 전체 고도화
Month 18+:   Phase 6 - 지속적 개선 및 확장
```

### 1.2 팀 구성

**DS 1명** (전담, 단독 수행)

담당 업무:

- 데이터 분석, 모델 개발
- ML 인프라 (SageMaker, Lambda, CDK)
- API 코드, 배치 작업
- 배포, 운영, 리포트

필요 자격 및 역량:

**학력/경력**:

- AI/ML 석사 이상 또는 실무 3년 이상
- 추천 시스템 개발 경험 (필수)
- 프로덕션 ML 모델 배포 경험

**기술 역량** (필수):

- Python, ML 라이브러리 (Scikit-learn, XGBoost, PyTorch)
- 추천 시스템 알고리즘 (Collaborative Filtering, Bandit, RL)
- 통계 및 A/B 테스트
- AWS (SageMaker, Lambda, DynamoDB 기본)

**우대 사항**:

- Contextual Bandit 또는 강화학습 경험
- Two-Tower 모델, ANN 검색 경험
- Cursor, Claude 등 AI 도구 활용 능숙자
- 백엔드 개발 경험 (FastAPI, NestJS)
- 스타트업 경험 (빠른 실행력)

**중요**: AI 도구는 "코드 생성"만 도와줄 뿐, **AI/ML 설계 및 판단은 전문가만 가능**

AI 도구 효과:

- 기존 3-4명분 → 1명이 수행
- 작업 속도 5-10배 향상
- 전문 영역 코드도 AI 생성

예시:

- 데이터 전처리: 3일 → 4시간
- 모델 코드: 5일 → 1일
- SageMaker 배포: 3일 → 6시간
- Lambda 배치: 2일 → 4시간

---

## 2. Phase 0: 서비스 출시 및 데이터 수집 (Month 0-3)

### 2.1 목표

- ✅ Level 1 전통적 박스 시스템 프로덕션 배포
- ✅ 기본 로그 수집 시스템 구축 및 안정화
- ✅ 최소 3개월 운영 데이터 확보

### 2.2 팀 역할

**유지보수 팀** (메인):

- 서비스 안정화
- 버그 수정
- 기능 개선

**AI 개발 팀** (보조):

- 로그 수집 검증
- 데이터 품질 모니터링
- 예비 분석

### 2.3 주요 작업

**Week 1-4: 서비스 출시**

```
✅ Level 1 박스 시스템 구현
  - 4개 박스 점수 계산 (매력도, 활동성, 수익유발, 지출)
  - DB 집계 쿼리 최적화
  - 추천 API 구현

✅ 기본 로그 시스템 구축
  - VIEW, LIKE, FRIEND_REQUEST, MATCH, PAYMENT 이벤트
  - DynamoDB 테이블 설계
  - 로그 수집 파이프라인

✅ 모니터링 대시보드
  - 일일 활성 사용자
  - 매칭률, 재화 소비율
  - 로그 수집 성공률
```

**Week 5-8: 안정화**

```
✅ 데이터 품질 검증
  - 로그 누락률 < 0.1%
  - 데이터 무결성 체크
  - 이상 패턴 감지

✅ 초기 분석
  - 사용자 행동 패턴 파악
  - 매칭 성공률 분석
  - 재화 소비 패턴 분석
```

**Week 9-12: 데이터 축적**

```
✅ 지속적 모니터링
  - 일일 데이터 리포트
  - 주간 트렌드 분석
  - 이상값 처리

✅ 예비 분석 (AI 팀)
  - 샘플 데이터로 예비 모델 실험
  - 피처 중요도 분석
  - Level 2 개발 계획 수립 시작
```

### 2.4 성공 기준

- [ ] 일일 활성 사용자 1,000명 이상
- [ ] 로그 수집 성공률 99.9% 이상
- [ ] 최소 100,000개 행동 이벤트 수집
- [ ] 최소 10,000개 매칭 이벤트 수집

### 2.5 산출물

- Level 1 프로덕션 시스템
- 3개월간 운영 로그 (100,000+ 이벤트)
- 초기 데이터 분석 리포트
- Level 2 개발 계획서 (초안)

### 2.6 다음 단계 진행 조건

**필수**:

- 로그 수집 안정화 (99.9% 성공률)
- 최소 3개월 데이터 확보
- 매칭 이벤트 10,000건 이상

**권장**:

- 일일 활성 사용자 2,000명 이상
- 다양한 사용자 세그먼트 데이터 확보

---

## 3. Phase 1: Level 2 준비 (Month 3-6)

### 3.1 목표

- ✅ 축적된 데이터 심층 분석
- ✅ Level 2 모델 우선순위 결정
- ✅ 첫 번째 모델 개발 계획 수립
- ✅ Level 2 로그 추가 (PREDICTION, MODEL_PERFORMANCE)

### 3.2 팀 역할

**AI 개발 (DS 1명)**:

- 데이터 분석 및 EDA
- 모델 설계
- 학습 계획 수립
- Level 2 로그 추가 구현 (AI 도구 활용)
- API 수정 (AI 도구로 코드 생성)

### 3.3 주요 작업

**Month 3: 데이터 분석**

```
Week 1-2: 탐색적 데이터 분석 (EDA)
  - 사용자 행동 패턴 분석
  - 좋아요/친구신청/수락 상관관계 분석
  - 이탈 패턴 분석
  - 피처 분포 확인

Week 3-4: 피처 엔지니어링
  - 유용한 피처 발굴
  - 피처 중요도 분석 (Random Forest 등)
  - 피처 상관관계 분석
  - 피처 정규화 전략
```

**Month 4: 모델 우선순위 결정 및 설계**

```
Week 1-2: 모델 우선순위 회의
  결정 기준:
  - 비즈니스 임팩트 (수익 기여도)
  - 데이터 충분성
  - 구현 난이도

  우선순위 결정 (예상):
  1. 친구 수락 확률 예측 (최우선)
     - 수익 직결
     - 데이터 충분 (10,000+ 이벤트)

  2. 이탈 확률 예측 (2순위)
     - 리텐션 중요
     - 데이터 충분

  3. 좋아요 확률 예측 (3순위)
     - 데이터 가장 많음 (50,000+ 이벤트)
     - 상대적으로 낮은 임팩트

Week 3-4: 모델 설계 문서 작성
  - Input/Output 명세 확정
  - 학습 알고리즘 후보 (Random Forest, XGBoost, Neural Net)
  - 성능 평가 지표 정의
  - 학습 데이터셋 분할 전략 (Train/Val/Test)
```

**Month 5-6: Level 2 로그 추가 및 인프라 준비**

```
Week 1-2: Level 2 로그 구현
  - PREDICTION 이벤트 추가
  - MODEL_PERFORMANCE 이벤트 추가
  - DynamoDB 테이블 스키마 확장

Week 3-4: ML 인프라 구축
  - SageMaker 환경 설정
  - S3 학습 데이터 버킷 생성
  - 학습 파이프라인 프로토타입

Week 5-6: 첫 모델 개발 착수
  - 친구 수락 확률 예측 모델 학습 시작
  - 소규모 실험 (10% 데이터)
  - 베이스라인 모델 구축
```

### 3.4 성공 기준

- [ ] Level 2 개발 계획서 완성
- [ ] 모델 우선순위 확정 (경영진 승인)
- [ ] Level 2 로그 시스템 구축 완료
- [ ] ML 인프라 준비 완료
- [ ] 친구 수락 모델 베이스라인 완성 (Accuracy 70%+)

### 3.5 산출물

- 데이터 분석 리포트
- Level 2 모델 개발 계획서
- Level 2 로그 시스템
- ML 인프라 (SageMaker, S3)
- 베이스라인 모델 (친구 수락 확률)

### 3.6 다음 단계 진행 조건

**필수**:

- 친구 수락 모델 베이스라인 70% 이상
- Level 2 로그 정상 수집 확인

**의사결정 포인트**:

- 데이터 품질 충분한가? (Yes → 진행, No → 3개월 더 수집)
- 베이스라인 성능 만족스러운가? (Yes → 진행, No → 피처 재검토)

---

## 4. Phase 2: Level 2 핵심 모델 개발 (Month 6-9)

### 4.1 목표

- ✅ 친구 수락 확률 예측 모델 프로덕션 수준 완성
- ✅ 이탈 확률 예측 모델 프로덕션 수준 완성
- ✅ 두 모델 A/B 테스트 준비

### 4.2 주요 작업

**Month 6: 모델 1 개발 (친구 수락 확률)**

```
Week 1-2: 데이터 전처리 및 피처 엔지니어링
  - 학습 데이터셋 생성
  - Train (60%) / Validation (20%) / Test (20%) 분할
  - 피처 정규화 및 인코딩
  - Negative sampling 전략 적용

Week 3-4: 모델 실험
  - 알고리즘 비교 (Random Forest, XGBoost, LightGBM, Neural Net)
  - 하이퍼파라미터 튜닝
  - Cross-validation
  - 성능 비교

  목표 성능:
  - Accuracy: 85%+
  - Precision: 0.80+
  - Recall: 0.75+
  - AUC: 0.90+
```

**Month 7: 모델 1 완성 및 배포**

```
Week 1-2: 모델 최적화
  - 최고 성능 모델 선택
  - 추론 속도 최적화 (목표: 50ms)
  - 모델 경량화

Week 3: SageMaker 배포
  - Endpoint 생성
  - 추론 API 구현
  - 로드 테스트

Week 4: 오프라인 검증
  - 실제 데이터로 재검증
  - 엣지 케이스 테스트
  - 성능 벤치마크
```

**Month 8: 모델 2 개발 (이탈 확률)**

```
Week 1-2: 데이터 준비
  - 이탈 정의 확정 (7일/30일 미접속)
  - Positive/Negative 샘플 생성
  - 피처 엔지니어링 (활동 추세 등)

Week 3-4: 모델 실험 및 최적화
  - 알고리즘 실험
  - 하이퍼파라미터 튜닝

  목표 성능:
  - AUC: 0.85+
  - 7일 이탈 예측: Precision 0.75+
  - 30일 이탈 예측: Precision 0.70+
```

**Month 9: 두 모델 통합 및 A/B 테스트 준비**

```
Week 1-2: 추론 파이프라인 통합
  - 두 모델을 하나의 API로 통합
  - 배치 추론 최적화
  - 캐싱 전략 구현

Week 3-4: A/B 테스트 설계
  - Control: Level 1만 (전통적 방식)
  - Treatment: Level 1 + 2 (AI 예측 활용)
  - 측정 지표 정의
  - 샘플 크기 계산
```

### 4.3 성공 기준

**모델 성능**:

- [ ] 친구 수락 예측: AUC 0.90+, Accuracy 85%+
- [ ] 이탈 예측: AUC 0.85+, Precision 0.75+
- [ ] 추론 시간: 50ms 이내

**시스템 안정성**:

- [ ] SageMaker Endpoint uptime 99.9%
- [ ] 추론 API 에러율 < 0.1%
- [ ] PREDICTION 로그 수집률 99%+

### 4.4 산출물

- 친구 수락 확률 예측 모델 (프로덕션)
- 이탈 확률 예측 모델 (프로덕션)
- 추론 API 및 파이프라인
- 모델 개발 기술 문서
- A/B 테스트 설계서

### 4.5 리스크 및 대응

**리스크 1**: 데이터 부족으로 성능 미달

- 징후: 베이스라인 대비 개선 < 10%
- 대응: 3개월 더 데이터 수집 또는 피처 재설계

**리스크 2**: 추론 속도 느림 (>100ms)

- 징후: 모델 복잡도 과다
- 대응: 모델 경량화 또는 캐싱 강화

### 4.6 의사결정 포인트 (Month 9 말)

**Go / No-Go 결정**:

```
Phase 3 진행 조건:
✅ 친구 수락 모델 AUC 0.85 이상
✅ 이탈 모델 AUC 0.80 이상
✅ 추론 시간 50ms 이내
✅ 시스템 안정성 확보

→ 조건 충족: Phase 3 진행 (A/B 테스트)
→ 조건 미충족: Phase 2 재시도 (2개월 추가)
```

---

## 5. Phase 3: Level 2 적용 및 검증 (Month 9-12)

### 5.1 목표

- ✅ Level 2 모델 A/B 테스트 실행
- ✅ 프로덕션 점진적 롤아웃
- ✅ 성과 측정 및 개선
- ✅ 나머지 Level 2 모델 개발 착수 (선택)

### 5.2 주요 작업

**Month 9-10: A/B 테스트**

```
Week 1-2: 10% 트래픽 A/B 테스트
  - Control (50%): Level 1만
  - Treatment (50%): Level 1 + 2 (친구 수락 + 이탈 예측)

  측정 지표:
  - 매칭 성공률
  - 사용자당 재화 소비 (ARPU)
  - 7일/30일 리텐션
  - 세션 빈도 및 시간

Week 3-4: 결과 분석
  - 통계적 유의성 검증
  - 세그먼트별 효과 분석 (남성/여성, 신규/기존)
  - 부작용 체크 (이탈률 증가 등)

Week 5-6: 조정 및 재실험
  - 발견된 문제 수정
  - 하이퍼파라미터 미세 조정
  - 20% 트래픽으로 재실험
```

**Month 11: 점진적 롤아웃**

```
Week 1: 50% 트래픽 적용
  - 모니터링 강화
  - 이상 패턴 즉시 대응

Week 2-3: 100% 롤아웃
  - 전체 사용자 적용
  - 성과 측정 지속

Week 4: 성과 리포트
  - 최종 효과 측정
  - ROI 계산
  - 경영진 보고
```

**Month 12: 안정화 및 추가 모델 검토**

```
Week 1-2: 모니터링 및 개선
  - 모델 성능 추적
  - 드리프트 감지
  - 필요시 재학습

Week 3-4: 추가 모델 개발 여부 결정
  옵션 A: 좋아요 확률 모델 추가 개발
    - Level 2 고도화
    - 3개월 소요 예상

  옵션 B: Level 3 개발 착수 (권장)
    - 수익 최적화가 더 큰 임팩트
    - 기존 2개 모델로 충분
```

### 5.3 성공 기준

**비즈니스 지표**:

- [ ] ARPU: +15% 이상 (목표: +20%)
- [ ] 7일 리텐션: 유지 또는 +5%
- [ ] 30일 리텐션: 유지 또는 +5%
- [ ] 매칭 성공률: -5% 이내

**기술 지표**:

- [ ] 모델 정확도 유지 (드리프트 < 5%)
- [ ] 추론 API 가용성 99.9%
- [ ] P95 응답시간 < 100ms

### 5.4 산출물

- A/B 테스트 결과 리포트
- Level 2 성과 분석 리포트
- 프로덕션 모델 (친구 수락 + 이탈)
- 모니터링 대시보드
- Level 3 개발 계획서 (초안)

### 5.5 의사결정 포인트 (Month 12 말)

**Level 3 개발 여부 결정**:

```
진행 조건:
✅ Level 2 성과 만족 (ARPU +15% 이상)
✅ 시스템 안정성 확보
✅ 추가 투자 가능 (인력, 예산)

선택지:
A. Level 2 고도화 (좋아요 모델 추가)
   - 예상 추가 효과: +5-10%
   - 기간: 3개월

B. Level 3 개발 착수 (권장)
   - 예상 효과: +25-40%
   - 기간: 3-6개월

C. 현상 유지
   - Level 2 모니터링만
   - AI 팀 축소

권장: B (Level 3 개발)
이유: 수익 최적화가 가장 큰 임팩트
```

---

## 6. Phase 4: Level 3 개발 (Month 12-15)

### 6.1 목표

- ✅ Level 3 수익 최적화 모델 개발
- ✅ Contextual Bandit 구현
- ✅ 전략 정의 및 검증
- ✅ Level 3 로그 추가 (EXPOSURE, REWARD)

### 6.2 주요 작업

**Month 12: Level 3 설계 및 준비**

```
Week 1-2: 전략 설계 워크숍
  - 기획팀 + AI팀 협업
  - 10-15개 전략 정의
  - 각 전략의 프로필 분포 비율 결정
  - 예: Balanced (높은 30% / 중간 50% / 탐색 20%)

Week 3-4: Level 3 로그 시스템 구현
  - EXPOSURE 이벤트 추가
  - Context 벡터 계산 로직
  - exposure_id 생성 및 저장
  - DynamoDB exposures 테이블 확장
```

**Month 13: 규칙 기반 전략 적용 (데이터 수집)**

```
Week 1-2: 규칙 기반 전략 선택 구현
  - IF-THEN 규칙
  - 예: IF churn_risk > 0.3 THEN Retention_Safe

Week 3-4: 데이터 수집 시작
  - EXPOSURE 이벤트 수집
  - 전략별 분포 확인
  - 초기 패턴 분석

목표: 최소 2개월 (Month 13-14) 데이터 수집
```

**Month 14: 보상 계산 시스템 구축**

```
Week 1-2: 보상 계산 로직 구현
  - 일일 배치: 7일 보상 계산
  - REWARD_AGGREGATION 이벤트 생성
  - rewards 테이블 저장

Week 3-4: 검증 및 안정화
  - 보상 계산 정확성 검증
  - 이상값 처리
  - 데이터 품질 체크
```

**Month 15: Contextual Bandit 개발**

```
Week 1-2: Bandit 알고리즘 구현
  - Thompson Sampling 구현
  - 베이지안 회귀 모델
  - 전략별 θ_k 학습

Week 3-4: 오프라인 검증
  - 과거 데이터로 시뮬레이션
  - 예상 성과 계산
  - 규칙 기반 vs Bandit 비교
```

### 6.3 성공 기준

**데이터 수집**:

- [ ] 최소 20,000개 EXPOSURE 이벤트
- [ ] 전략당 최소 2,000개 샘플
- [ ] 보상 계산 성공률 99%+

**Bandit 모델**:

- [ ] 오프라인 시뮬레이션: 규칙 대비 +15% 수익
- [ ] 전략별 θ_k 수렴 확인
- [ ] 추론 시간 30ms 이내

### 6.4 산출물

- 10-15개 전략 정의 문서
- Level 3 로그 시스템
- 보상 계산 배치 작업
- Contextual Bandit 모델
- 오프라인 검증 리포트

---

## 7. Phase 5: Level 3 적용 및 전체 고도화 (Month 15-18)

### 7.1 목표

- ✅ Level 3 A/B 테스트 및 롤아웃
- ✅ Level 1 + 2 + 3 통합 시스템 완성
- ✅ 나머지 Level 2 모델 추가 (선택)

### 7.2 주요 작업

**Month 15-16: Level 3 A/B 테스트**

```
Week 1-2: 20% 트래픽 A/B 테스트
  - Control (50%): Level 1 + 2 (규칙 기반 전략)
  - Treatment (50%): Level 1 + 2 + 3 (Bandit)

  측정 지표:
  - ARPU (최우선)
  - LTV 추정
  - 리텐션
  - 이탈률
  - 사용자 만족도

Week 3-4: 결과 분석 및 조정
  - 통계적 유의성 검증
  - 세그먼트별 효과
  - 문제점 수정
```

**Month 17: 점진적 롤아웃**

```
Week 1: 50% 롤아웃
Week 2: 80% 롤아웃
Week 3: 100% 롤아웃
Week 4: 성과 측정 및 리포트
```

**Month 18: 고도화 및 확장**

```
Week 1-2: 주간 자동 재학습 구축
  - 파이프라인 자동화
  - 성능 모니터링
  - 자동 롤백 메커니즘

Week 3-4: 추가 모델 개발 (선택)
  - 좋아요 확률 예측
  - 채팅 응답 확률 예측
  - 우선순위에 따라 결정
```

### 7.3 성공 기준

**비즈니스 목표 (핵심)**:

- [ ] ARPU: +25% 이상 (vs Phase 0 베이스라인)
- [ ] LTV: +30% 이상
- [ ] 30일 리텐션: -5% 이내
- [ ] 매칭 성공률: -10% 이내

**시스템 안정성**:

- [ ] 전체 파이프라인 가용성 99.9%
- [ ] 주간 재학습 성공률 100%
- [ ] 이상 패턴 조기 감지 (24시간 이내)

### 7.4 산출물

- Level 3 프로덕션 시스템
- A/B 테스트 최종 리포트
- 자동 재학습 파이프라인
- 통합 모니터링 대시보드
- AI 시스템 운영 매뉴얼

---

## 8. Phase 6: 지속적 개선 (Month 18+)

### 8.1 목표

- ✅ 시스템 안정적 운영
- ✅ 주간 자동 재학습
- ✅ 새로운 전략 실험
- ✅ 강화학습 전환 검토 (장기)

### 8.2 주요 작업

**정기 작업 (지속)**:

```
주간:
- Bandit 모델 재학습
- 전략별 성과 리뷰
- 이상 패턴 대응

월간:
- 전략 효과성 분석
- 신규 전략 추가/제거 검토
- 성과 리포트 (경영진)

분기:
- 전략 포트폴리오 재조정
- Level 2 모델 추가 개발 검토
- 강화학습 전환 가능성 평가
```

**고도화 옵션**:

```
Option 1: Level 2 모델 확장
  - 좋아요 확률 예측
  - 채팅 응답 확률 예측
  - 데이트 신청 확률 예측

Option 2: Level 3 고도화
  - 전략 개수 확장 (15개 → 20개)
  - Two-Tower 모델 도입 (확장성)
  - 실시간 재학습

Option 3: 강화학습 전환 (장기)
  - DQN 또는 PPO
  - 시뮬레이션 환경 구축
  - 조건: 데이터 100만+ 건, 전담 팀
```

---

## 9. 단계별 리소스 및 예산

### 9.1 인력 (AI 도구 활용 기준)

| Phase   | 기간        | DS (전담) | 백엔드 지원 (내부) | 주요 작업                  | AI 도구 효과           |
| ------- | ----------- | --------- | ------------------ | -------------------------- | ---------------------- |
| Phase 0 | Month 0-3   | 0.3명     | -                  | 데이터 모니터링, 예비 분석 | 분석 코드 자동 생성    |
| Phase 1 | Month 3-6   | 1명       | 2주 (Month 5-6)    | 분석, 계획, SageMaker 설정 | EDA, 인프라 코드 생성  |
| Phase 2 | Month 6-9   | 1명       | 1주 (API 수정)     | 모델 개발                  | 모델 코드 자동 생성    |
| Phase 3 | Month 9-12  | 1명       | 1주 (API 통합)     | A/B 테스트, 분석           | 통계 분석, 리포트 자동 |
| Phase 4 | Month 12-15 | 1명       | 2주 (로그 추가)    | Level 3 개발               | Bandit 코드 생성       |
| Phase 5 | Month 15-18 | 1명       | 2주 (파이프라인)   | 롤아웃, 자동화 구축        | 배치 작업 코드 자동화  |
| Phase 6 | Month 18+   | 0.5명     | 필요시 1주         | 유지보수                   | 거의 자동화            |

**핵심**:

- **DS 1명이 거의 모든 것을 수행**

  - 데이터 분석
  - 모델 설계 및 개발
  - 학습 파이프라인 구축
  - SageMaker 설정 및 배포
  - 배치 작업 개발
  - 성과 분석 및 리포트

- **백엔드 팀 지원** (기존 인력, 최소한만)
  - SageMaker 초기 설정 리뷰 (Month 5-6, 2주)
  - API 수정 (각 Phase 1주씩, 총 6주)
  - 인프라 배포 승인 (Month 17-18, 2주)
- **AI 도구 덕분에 DS 혼자 가능**
  - 코드 대부분 AI가 자동 생성
  - 백엔드는 리뷰만
  - 별도 MLOps 채용 불필요

### 9.2 예산 (월간, 원화)

| 항목                     | Phase 0-1   | Phase 2-3   | Phase 4-5     | Phase 6     |
| ------------------------ | ----------- | ----------- | ------------- | ----------- |
| 인건비 (DS 1명)          | 830만원     | 830만원     | 830만원       | 420만원     |
| SageMaker                | 13만원      | 65만원      | 100만원       | 65만원      |
| S3 스토리지              | 7만원       | 13만원      | 20만원        | 20만원      |
| DynamoDB                 | 13만원      | 26만원      | 40만원        | 40만원      |
| AI 도구 (Cursor, Claude) | 7만원       | 13만원      | 13만원        | 7만원       |
| 기타 (CloudWatch 등)     | 7만원       | 13만원      | 20만원        | 13만원      |
| **총계**                 | **877만원** | **960만원** | **1,023만원** | **565만원** |

**18개월 예산 총합** (추정):

- DS 인건비: 1억원/년 × 1.5년 = 1.5억원
- AWS 인프라 (SageMaker, S3, DynamoDB): 2,500만원
- AI 도구 (Cursor Pro, Claude API): 1,500만원
- 기타 (CloudWatch, 교육 등): 1,000만원
- **총 예산**: **약 2억원**

**비교**:

- AI 도구 없을 때: 약 4억원 (DS 2명 + MLOps 1명 × 18개월)
- AI 도구 활용: 약 2억원
- **절감**: 약 2억원 (50%)

---

## 10. 위험 관리 및 대응

### 10.1 주요 리스크

**리스크 1: 데이터 부족**

- 시점: Phase 1
- 징후: 이벤트 수 < 목표의 50%
- 대응: 프로모션으로 사용자 활성화 또는 일정 연기

**리스크 2: 모델 성능 미달**

- 시점: Phase 2
- 징후: AUC < 0.80
- 대응: 피처 재설계 또는 알고리즘 변경

**리스크 3: A/B 테스트 실패**

- 시점: Phase 3, 5
- 징후: 개선 효과 < 5%
- 대응: 원인 분석 후 재설계 또는 중단

**리스크 4: 시스템 불안정**

- 시점: Phase 3, 5
- 징후: 에러율 > 1%, 응답시간 > 300ms
- 대응: 즉시 롤백, 성능 최적화 후 재배포

### 10.2 의사결정 체크포인트

각 Phase 종료 시 **Go / No-Go 결정**:

```
Month 3 (Phase 0 → 1):
- 데이터 충분? → Yes: 진행, No: 3개월 연장

Month 6 (Phase 1 → 2):
- 모델 개발 계획 확정? → Yes: 진행, No: 1개월 연장

Month 9 (Phase 2 → 3):
- 모델 성능 목표 달성? → Yes: 진행, No: 재개발

Month 12 (Phase 3 → 4):
- Level 2 효과 검증? → Yes: Level 3, No: Level 2 고도화

Month 15 (Phase 4 → 5):
- Bandit 모델 준비? → Yes: 진행, No: 3개월 연장

Month 18 (Phase 5 → 6):
- Level 3 목표 달성? → Yes: 유지보수, No: 재조정
```

---

## 11. 모델 개발 우선순위 전략

### 11.1 Level 2 모델 우선순위

**1순위: 친구 수락 확률 예측**

- 이유: 수익 직결 (친구 신청 4-6재화)
- 데이터: 충분 (10,000+ 이벤트)
- 난이도: 중간
- 기간: 1개월

**2순위: 이탈 확률 예측**

- 이유: 리텐션 중요
- 데이터: 충분
- 난이도: 중간
- 기간: 1개월

**3순위: 좋아요 확률 예측**

- 이유: 데이터 가장 많음
- 데이터: 매우 충분 (50,000+ 이벤트)
- 난이도: 낮음
- 기간: 1개월
- 시점: Phase 5 또는 Phase 6

**4순위: 채팅 응답 확률 예측**

- 이유: 매칭 품질 개선
- 데이터: 보통 (5,000+ 이벤트)
- 난이도: 중간
- 시점: Phase 6

**권장**: 1, 2순위만 개발 후 Level 3로 진행. 3, 4순위는 선택적.

### 11.2 개발 전략

**집중 전략 (권장)**:

```
Month 6-9: Level 2 핵심 2개 개발
Month 12-15: Level 3 개발
Month 18+: 안정화 후 Level 2 추가 모델 검토

장점:
- 빠른 수익 최적화 (Level 3가 핵심)
- 리소스 집중
- 리스크 분산

단점:
- Level 2 모델 불완전
```

**완성 전략 (비권장)**:

```
Month 6-12: Level 2 모든 모델 개발 (6개)
Month 12-15: Level 3 개발
Month 15-18: 통합

장점:
- Level 2 완전체

단점:
- 수익 최적화 지연 (6개월)
- 리소스 과다 소모
- 일부 모델은 효과 미미할 수 있음
```

**권장**: 집중 전략

---

## 12. 성과 추적 및 보고

### 12.1 단계별 목표

| Phase   | 주요 지표   | 목표             | 측정 방법     |
| ------- | ----------- | ---------------- | ------------- |
| Phase 0 | 데이터 수집 | 100,000+ 이벤트  | DynamoDB 집계 |
| Phase 1 | 모델 계획   | 계획서 승인      | 경영진 리뷰   |
| Phase 2 | 모델 성능   | AUC 0.85+        | 테스트셋 평가 |
| Phase 3 | ARPU 개선   | +15%             | A/B 테스트    |
| Phase 4 | Bandit 준비 | 20,000+ exposure | DynamoDB 집계 |
| Phase 5 | 수익 최적화 | ARPU +25%        | A/B 테스트    |
| Phase 6 | 안정화      | 목표 유지        | 주간 리포트   |

### 12.2 보고 주기

**주간** (AI 팀 내부):

- 개발 진행 상황
- 데이터 품질 체크
- 이슈 및 블로커

**월간** (경영진):

- 단계별 진행률
- 주요 마일스톤 달성 여부
- 다음 달 계획

**분기** (전사):

- 비즈니스 성과 (ARPU, LTV, 리텐션)
- ROI 계산
- 다음 분기 전략

---

## 13. 의사결정 트리

### 13.1 핵심 의사결정 포인트

```
Month 3: 데이터 충분?
├─ Yes: Phase 1 진행
└─ No: 3개월 연장 → Month 6 재평가

Month 9: Level 2 성능 목표 달성?
├─ Yes: Phase 3 진행 (A/B 테스트)
└─ No: 재개발 또는 중단

Month 12: Level 2 효과 검증?
├─ Yes: Level 3 개발
│   ├─ ARPU +15%+: Level 3 진행 (권장)
│   └─ ARPU +5-15%: Level 2 고도화 검토
└─ No (<+5%): Level 2 재설계 또는 중단

Month 15: Bandit 준비 완료?
├─ Yes: Phase 5 진행
└─ No: 3개월 연장

Month 18: Level 3 목표 달성?
├─ Yes: 유지보수 모드
│   └─ ARPU +25%+: 성공, 지속 운영
└─ No: 원인 분석 후 재조정
```

### 13.2 중단 기준

**프로젝트 중단 고려 상황**:

```
1. Phase 3에서 Level 2 효과 < +5%
   → 비용 대비 효과 미미
   → AI 투자 중단, 현상 유지

2. Phase 5에서 Level 3 효과 < +10% (Level 2 대비)
   → Bandit 효과 미미
   → Level 2만 유지

3. 시스템 불안정 지속 (에러율 > 1%)
   → 기술적 실현 불가능
   → 단순 방식으로 회귀
```

---

## 14. 빠른 참조: 타임라인 요약

```
서비스 출시 (M0)
    ↓
  [3개월 데이터 수집]
    ↓
Level 2 준비 시작 (M3)
    ↓
  [3개월 모델 개발]
    ↓
Level 2 첫 모델 완성 (M6)
    ↓
  [3개월 테스트 및 적용]
    ↓
Level 2 프로덕션 (M9)
    ↓
  [의사결정: Level 3 or Level 2 고도화?]
    ↓
Level 3 개발 시작 (M12, 권장)
    ↓
  [3개월 Bandit 개발]
    ↓
Level 3 A/B 테스트 (M15)
    ↓
  [3개월 롤아웃 및 안정화]
    ↓
전체 시스템 완성 (M18)
    ↓
  [지속적 개선]
```

---

## 15. 각 Phase별 주요 질문과 답변

### Phase 0 (Month 0-3)

**Q: 지금 당장 AI 개발 시작하면 안 되나요?**

A: 안 됩니다. 최소 3개월 데이터가 필요합니다.

- AI 학습 데이터 부족 (10,000+ 이벤트 필요)
- 사용자 행동 패턴 미파악
- 급하게 시작하면 성능 낮고 재작업 필요

### Phase 1 (Month 3-6)

**Q: 왜 Level 2 모델을 전부 안 만들고 2개만?**

A: 2개로 충분하고, 빠르게 Level 3로 가는 게 수익에 유리합니다.

- 친구 수락 + 이탈 예측이 핵심
- 나머지 모델은 부가적 효과
- Level 3가 수익 최적화의 핵심

### Phase 3 (Month 9-12)

**Q: Level 2 고도화 vs Level 3 개발, 어느 것?**

A: **Level 3 개발 권장**

- Level 2 추가 모델: 예상 효과 +5-10%
- Level 3 수익 최적화: 예상 효과 +25-40%
- Level 3가 훨씬 큰 임팩트

### Phase 5 (Month 15-18)

**Q: Level 3 A/B 테스트 실패하면?**

A: 원인 분석 후 재설계 또는 Level 2로 회귀

- 전략 설계 문제: 전략 재정의
- 데이터 문제: 3개월 더 수집
- 알고리즘 문제: Bandit → RL 검토
- 최악: Level 2만 유지 (그래도 +15% 효과)

---

## 16. 최종 권장사항

### 16.1 핵심 전략

**빠른 가치 창출**:

1. Level 2 핵심 2개만 개발 (친구 수락, 이탈)
2. 빠르게 Level 3로 전환
3. Level 3에서 수익 최대화

**단계적 검증**:

1. 각 Phase마다 명확한 성공 기준
2. Go/No-Go 의사결정 포인트
3. 실패 시 롤백 또는 재설계

**리스크 최소화**:

1. 작은 규모로 시작 (10% A/B 테스트)
2. 점진적 롤아웃 (10% → 50% → 100%)
3. 자동 롤백 메커니즘

### 16.2 타임라인 목표

**최소 목표** (보수적):

- Month 12: Level 2 프로덕션 (ARPU +15%)
- Month 18: Level 3 프로덕션 (ARPU +25%)

**이상적 목표** (적극적):

- Month 9: Level 2 프로덕션 (ARPU +20%)
- Month 15: Level 3 프로덕션 (ARPU +30%)

**권장**: 이상적 목표를 지향하되, 각 체크포인트에서 유연하게 조정

### 16.3 즉시 착수 사항

**지금 바로**:

1. AI 개발팀 구성 (데이터 사이언티스트 1명 채용 시작)
2. 데이터 품질 모니터링 강화
3. Phase 1 준비 (Month 3부터 본격 시작)

**Month 3 (3개월 후)**:

1. 축적된 데이터 분석 시작
2. Level 2 개발 계획 수립
3. MLOps 엔지니어 채용

---

## 부록 A: 상세 작업 체크리스트

### Phase 0 (Month 0-3)

데이터 수집:

- [ ] VIEW 이벤트 로깅
- [ ] LIKE/SUPER_LIKE 이벤트
- [ ] FRIEND_REQUEST 이벤트
- [ ] MATCH 이벤트
- [ ] PAYMENT 이벤트
- [ ] 로그 수집률 99%+ 달성

모니터링:

- [ ] CloudWatch 대시보드
- [ ] 일일 데이터 품질 리포트
- [ ] 주간 집계 리포트

### Phase 1 (Month 3-6)

분석:

- [ ] EDA 완료
- [ ] 피처 엔지니어링
- [ ] 피처 중요도 분석

계획:

- [ ] 모델 우선순위 확정
- [ ] 개발 계획서 작성
- [ ] 경영진 승인

준비:

- [ ] Level 2 로그 추가
- [ ] SageMaker 환경 구축
- [ ] 학습 파이프라인 프로토타입

### Phase 2 (Month 6-9)

모델 개발:

- [ ] 친구 수락 모델 완성
- [ ] 이탈 예측 모델 완성
- [ ] SageMaker 배포
- [ ] 추론 API 구현

검증:

- [ ] 테스트셋 평가
- [ ] 오프라인 검증
- [ ] 성능 벤치마크

### Phase 3 (Month 9-12)

A/B 테스트:

- [ ] 10% 트래픽 테스트
- [ ] 결과 분석
- [ ] 50% 롤아웃
- [ ] 100% 롤아웃

성과:

- [ ] ARPU +15% 달성
- [ ] 리텐션 유지
- [ ] 성과 리포트

### Phase 4 (Month 12-15)

Level 3 준비:

- [ ] 전략 10-15개 정의
- [ ] Level 3 로그 추가
- [ ] 규칙 기반 전략 적용
- [ ] 2개월 데이터 수집

Bandit 개발:

- [ ] 보상 계산 시스템
- [ ] Thompson Sampling 구현
- [ ] 오프라인 검증

### Phase 5 (Month 15-18)

Level 3 적용:

- [ ] A/B 테스트 (20%)
- [ ] 점진적 롤아웃
- [ ] 주간 재학습 자동화
- [ ] ARPU +25% 달성

---

## 부록 B: 월별 상세 계획

### Month 0-3: 서비스 출시 및 데이터 수집

| 주차  | 주요 작업                 | 담당         | 산출물           |
| ----- | ------------------------- | ------------ | ---------------- |
| W1-2  | 서비스 출시, Level 1 구현 | 전체 팀      | 프로덕션 시스템  |
| W3-4  | 로그 시스템 안정화        | Backend      | 로그 파이프라인  |
| W5-8  | 모니터링 및 품질 관리     | Backend + AI | 대시보드         |
| W9-12 | 데이터 축적 및 예비 분석  | AI           | 초기 분석 리포트 |

### Month 3-6: Level 2 준비

| 주차   | 주요 작업          | 담당      | 산출물         |
| ------ | ------------------ | --------- | -------------- |
| W1-2   | EDA 및 데이터 분석 | AI        | 분석 리포트    |
| W3-4   | 피처 엔지니어링    | AI        | 피처 목록      |
| W5-6   | 모델 우선순위 결정 | AI + 기획 | 우선순위 문서  |
| W7-8   | 개발 계획 수립     | AI        | 개발 계획서    |
| W9-10  | Level 2 로그 구현  | Backend   | 로그 시스템    |
| W11-12 | ML 인프라 구축     | MLOps     | SageMaker 환경 |

### Month 6-9: Level 2 모델 개발

| 주차   | 주요 작업           | 담당       | 산출물             |
| ------ | ------------------- | ---------- | ------------------ |
| W1-4   | 친구 수락 모델 개발 | AI         | 모델 v1.0          |
| W5-8   | 이탈 예측 모델 개발 | AI         | 모델 v1.0          |
| W9-10  | 통합 및 배포        | AI + MLOps | SageMaker Endpoint |
| W11-12 | 오프라인 검증       | AI         | 검증 리포트        |

### Month 9-12: Level 2 적용

| 주차   | 주요 작업                 | 담당      | 산출물                    |
| ------ | ------------------------- | --------- | ------------------------- |
| W1-2   | 10% A/B 테스트            | 전체      | A/B 결과 (중간)           |
| W3-4   | 분석 및 조정              | AI        | 개선 리포트               |
| W5-6   | 20% 재테스트              | 전체      | A/B 결과 (확장)           |
| W7-8   | 50% 롤아웃                | 전체      | 성과 측정                 |
| W9-10  | 100% 롤아웃               | 전체      | 최종 배포                 |
| W11-12 | 성과 분석 및 Level 3 계획 | AI + 기획 | 성과 리포트, Level 3 계획 |

### Month 12-15: Level 3 개발

| 주차   | 주요 작업           | 담당         | 산출물           |
| ------ | ------------------- | ------------ | ---------------- |
| W1-2   | 전략 정의 워크숍    | AI + 기획    | 전략 10-15개     |
| W3-4   | Level 3 로그 구현   | Backend      | EXPOSURE 시스템  |
| W5-8   | 규칙 기반 전략 적용 | AI           | 데이터 수집 시작 |
| W9-10  | 보상 계산 시스템    | Backend + AI | 배치 작업        |
| W11-12 | Bandit 개발         | AI           | Bandit 모델 v1.0 |

### Month 15-18: Level 3 적용

| 주차   | 주요 작업        | 담당  | 산출물          |
| ------ | ---------------- | ----- | --------------- |
| W1-2   | 오프라인 검증    | AI    | 시뮬레이션 결과 |
| W3-4   | 20% A/B 테스트   | 전체  | A/B 결과        |
| W5-6   | 50% 롤아웃       | 전체  | 성과 측정       |
| W7-8   | 100% 롤아웃      | 전체  | 최종 배포       |
| W9-10  | 자동 재학습 구축 | MLOps | 파이프라인      |
| W11-12 | 최종 성과 분석   | AI    | 최종 리포트     |

---

## 부록 C: 주요 마일스톤

| 마일스톤 | 시점     | 내용              | 성공 기준        |
| -------- | -------- | ----------------- | ---------------- |
| M1       | Month 3  | 데이터 수집 완료  | 100,000+ 이벤트  |
| M2       | Month 6  | Level 2 계획 확정 | 계획서 승인      |
| M3       | Month 9  | Level 2 모델 완성 | AUC 0.85+        |
| M4       | Month 12 | Level 2 효과 검증 | ARPU +15%        |
| M5       | Month 15 | Level 3 모델 완성 | 오프라인 +15%    |
| M6       | Month 18 | Level 3 효과 검증 | ARPU +25% (총합) |

---

## 부록 D: 실패 시나리오 및 대응

### 시나리오 1: Month 9에 Level 2 효과 미미 (+5% 미만)

**원인 분석**:

- 데이터 품질 문제?
- 모델 설계 문제?
- 비즈니스 가정 오류?

**대응 옵션**:

1. 피처 재설계 후 재학습 (2개월)
2. 알고리즘 변경 (Neural Net → Ensemble)
3. 프로젝트 중단 (비용 대비 효과 낮음)

### 시나리오 2: Month 12에 Level 2 성공하지만 리소스 부족

**상황**: ARPU +15% 달성했으나 AI 팀 확장 불가

**대응**:

- Level 3 개발 연기
- Level 2 유지보수만 지속
- 회사 규모 확대 시 재개

### 시나리오 3: Month 18에 Level 3 효과 미미 (+5% 미만, Level 2 대비)

**원인 분석**:

- 전략 설계 부적절?
- 보상 함수 설계 오류?
- Bandit 알고리즘 문제?

**대응 옵션**:

1. 전략 재설계 (3개월)
2. 보상 함수 조정 (1개월)
3. 강화학습으로 전환 (6개월)
4. Level 2로 회귀 (Bandit 포기)

---

## 부록 E: 예산 총합

### 18개월 총 예산 (추정)

| 항목                      | 금액         | 비고                      |
| ------------------------- | ------------ | ------------------------- |
| 인건비 (DS 1명 × 18개월)  | 1.5억원      | 연 1억원                  |
| AWS 인프라 (18개월)       | 2,500만원    | SageMaker, S3, DynamoDB   |
| AI 도구 라이선스 (18개월) | 1,500만원    | Cursor Pro, Claude API 등 |
| 기타 (교육, 컨퍼런스 등)  | 1,000만원    | -                         |
| **총계**                  | **약 2억원** | -                         |

**비교**:

- AI 도구 없을 때: 약 4억원 (DS 2명 + MLOps 1명)
- AI 도구 활용: 약 2억원
- **절감**: 약 2억원 (50%)

### ROI 계산 (추정)

```
투자: 2억원 (18개월)

수익 증가 (보수적 추정):
- ARPU +25%: 12,000원 → 15,000원 (+3,000원)
- 월간 활성 사용자 평균: 10,000명
- 월 추가 수익: 3,000원 × 10,000명 = 3,000만원
- 연 추가 수익: 3.6억원

ROI: 3.6억원 / 2억원 = 1.8배 (첫 해)
회수 기간: 약 7개월

2년차 이후:
- 연 추가 수익: 3.6억원
- 연 유지 비용: 0.7억원 (DS 0.5명 + 인프라)
- 순수익: 2.9억원/년
```

**핵심**: AI 도구로 비용 50% 절감 + 빠른 회수 기간

---

## 최종 결론

**추천 로드맵**:

1. **지금 (Month 0-3)**: 데이터 수집 집중
2. **Month 3-9**: Level 2 핵심 2개 개발 및 적용
3. **Month 9-12**: 성과 검증 후 Level 3 결정
4. **Month 12-18**: Level 3 개발 및 적용
5. **Month 18+**: 안정화 및 지속 개선

**핵심 원칙**:

- 단계적 검증: 각 Phase마다 성공 확인 후 진행
- 빠른 가치 창출: 핵심 모델 우선, 부가 모델은 나중에
- 리스크 관리: 작게 시작, 검증 후 확대
- **AI 도구 적극 활용**: DS 1명으로 전체 로드맵 실행

**리소스 (AI 도구 활용)**:

- **인력**: DS 1명 단독 수행
- **예산**: 총 2억원 (18개월)
- **AI 도구 효과**: 개발 속도 5-10배, 비용 50% 절감

**예상 성과**:

- Month 12: ARPU +15-20% (Level 2)
- Month 18: ARPU +25-35% (Level 3 추가)
- ROI: 1.8배 (첫 해), 4배+ (2년차)
- 회수 기간: 7개월

**성공 요인**:

1. **AI 도구**: Cursor, Claude로 개발 속도 10배 향상
2. **집중 전략**: 핵심만 개발 (Level 2는 2개만)
3. **빠른 전환**: Level 2 → Level 3 빠르게 (수익 최적화가 핵심)

**즉시 착수 사항**:

1. **지금**: DS 1명 채용 시작 (AI 도구 능숙자 우대)
2. **Month 3**: 데이터 분석 착수
3. **Month 6**: Level 2 모델 개발 시작

이 로드맵으로 **최소 인력, 최소 비용, 최대 효과**를 달성할 수 있습니다.
