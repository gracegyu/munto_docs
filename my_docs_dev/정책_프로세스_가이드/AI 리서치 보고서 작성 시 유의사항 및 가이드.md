## 목적

본 문서는 AI(Generative AI, Large Language Model)를 활용한 리서치 결과를 내부 보고서나 과업 결과물로 제출할 때, 유의해야 할 사항과 실질적인 보완 방법을 안내하기 위해 작성되었습니다.

## 주요 유의사항

1. **AI는 오류 가능성이 존재함**
   - AI는 실제와 다른 내용을 허위로 생성할 수 있으며, 그럴듯한 표현으로 오인될 위험이 있습니다. 검증 없이 제출할 경우, 문서의 전문성과 신뢰도를 크게 저하시킬 수 있습니다.
2. **최신 정보가 반영되지 않을 수 있음**
   - 대부분의 AI는 학습 시점 이후의 정보가 반영되지 않으며, AWS와 같은 클라우드 서비스처럼 지속적으로 변화하는 영역에서는 최신 기능이나 UI가 누락될 수 있습니다.
3. **Agent 및 Plugin의 한계**
   - 실시간 검색 기능이 탑재된 Agent나 Plugin을 사용하더라도, 검색 결과가 편향되었거나 정확하지 않을 수 있습니다. 출처 확인 및 교차 검토가 필요합니다.
4. **사용자 해석과 요약이 필요함**
   - AI가 제공한 정보는 참고자료로 활용하고, 반드시 실제 테스트 결과나 직접 검토한 내용을 기반으로 본인의 언어로 재정리해야 합니다.
5. **보고서에는 본인의 기여가 드러나야 함**
   - AI 대화 내용을 그대로 제출하지 말고, 활용한 부분은 명확히 구분하고, 분석·해석·결론은 본인의 판단에 기반해 작성해야 합니다.

## 보완 전략

- **다양한 AI 모델로 교차 검증**
  동일 질문을 GPT-4o, Claude, Perplexity 등 여러 모델에 질문하고, 응답의 일관성 및 정확성을 비교하여 신뢰도를 높입니다.
- **실시간 검색 기반 도구 활용**
  Perplexity, Bing Copilot, Web 기반 GPT 기능 등을 통해 최신성 확보. 단, 출처(URL 등)는 반드시 명시합니다.
- **직접 사용 후 분석 결과 포함**
  추천된 툴이나 서비스는 반드시 사용해 보고 장단점, 적용 가능성 등을 정리하여 결과 보고서에 포함합니다.

## 결론

AI는 리서치와 브레인스토밍 단계에서 유용한 도구이지만, 최종 결과물은 사용자의 해석과 판단이 반영되어야 합니다. AI가 제공한 정보는 "출발점"일 뿐이며, "최종 결론"은 사람이 책임지고 작성해야 합니다. 본 가이드를 통해 더 신뢰도 높은 보고서를 작성할 수 있기를 바랍니다.
